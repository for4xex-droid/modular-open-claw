use tokio_cron_scheduler::{Job, JobScheduler};
use tracing::{info, warn, error};
use std::sync::Arc;
use factory_core::traits::JobQueue;
use infrastructure::job_queue::SqliteJobQueue;
use rig::providers::gemini;
use rig::completion::Prompt;
use rig::client::CompletionClient;
use tokio::fs;
use factory_core::contracts::LlmJobResponse;

use tokio::sync::mpsc;
use shared::watchtower::CoreEvent;

fn compute_soul_hash(soul_content: &str) -> String {
    use std::hash::{Hash, Hasher};
    let mut hasher = std::collections::hash_map::DefaultHasher::new();
    soul_content.hash(&mut hasher);
    format!("{:16x}", hasher.finish())
}

pub async fn start_cron_scheduler(
    job_queue: Arc<SqliteJobQueue>,
    log_tx: mpsc::Sender<CoreEvent>,
    ollama_url: String,
    model_name: String,
    brave_api_key: String,
    youtube_api_key: String,
    gemini_api_key: String,
    soul_md: String,
    workspace_dir: String,
    comfyui_base_dir: String,
    clean_after_hours: u64,
) -> Result<JobScheduler, Box<dyn std::error::Error + Send + Sync>> {
    let sched = JobScheduler::new().await?;

    // === Job 1: The Samsara Protocol â€” Runs daily at 07:00 and 19:00 ===
    let jq_samsara = job_queue.clone();
    let gem_key_samsara = gemini_api_key.clone();
    let brave_key_samsara = brave_api_key.clone();
    sched.add(
        Job::new_async("0 0 7,19 * * *", move |_uuid, mut _l| {
            let jq = jq_samsara.clone();
            let gem_key = gem_key_samsara.clone();
            let brave_key = brave_key_samsara.clone();
            
            Box::pin(async move {
                info!("ğŸ”„ [Samsara] Cron triggered. Initiating synthesis...");
                match synthesize_next_job(&gem_key, "gemini-2.5-flash", &brave_key, &*jq).await {
                    Ok(_) => info!("âœ… [Samsara] Successfully synthesized and enqueued next job."),
                    Err(e) => error!("âŒ [Samsara] Failed to synthesize next job: {}", e),
                }
            })
        })?
    ).await?;

    // === Job 2: The Zombie Hunter â€” Runs every 15 minutes ===
    let jq_zombie = job_queue.clone();
    sched.add(
        Job::new_async("0 */15 * * * *", move |_uuid, mut _l| {
            let jq = jq_zombie.clone();
            Box::pin(async move {
                match jq.reclaim_zombie_jobs(15).await {
                    Ok(count) => {
                        if count > 0 {
                            warn!("ğŸ§Ÿ [Zombie Hunter] Reclaimed {} ghost job(s)", count);
                        }
                    }
                    Err(e) => error!("âŒ [Zombie Hunter] Failed to reclaim: {}", e),
                }
            })
        })?
    ).await?;

    // === Job 3: Deferred Distillation â€” Runs every 5 minutes ===
    let jq_distill = job_queue.clone();
    let s_md_distill = soul_md.clone();
    let gem_key_distill = gemini_api_key.clone();
    let ws_dir_distill = workspace_dir.clone();
    sched.add(
        Job::new_async("0 */5 * * * *", move |_uuid, mut _l| {
            let jq = jq_distill.clone();
            let s_md = s_md_distill.clone();
            let gem_key = gem_key_distill.clone();
            let ws_dir = ws_dir_distill.clone();

            Box::pin(async move {
                match jq.fetch_undistilled_jobs(5).await {
                    Ok(jobs) => {
                        for job in jobs {
                            let is_success = job.status == factory_core::traits::JobStatus::Completed;
                            let log = job.execution_log.unwrap_or_default();
                            info!("ğŸ§˜ [Deferred Distillation] Processing undistilled Job: {}", job.id);
                            // Attempt distillation. If LLM is still down, the job stays undistilled and will be retried next cycle.
                            match distill_karma(
                                &gem_key, "gemini-2.5-flash",
                                &*jq, &job.id, &job.style, &log, is_success, job.creative_rating, &s_md, &ws_dir
                            ).await {
                                Ok(_) => {
                                    // Mark as distilled via trait method
                                    let _ = jq.mark_karma_extracted(&job.id).await;
                                    info!("âœ… [Deferred Distillation] Karma extracted for Job {}", job.id);
                                }
                                Err(e) => warn!("âš ï¸ [Deferred Distillation] LLM unavailable, will retry: {}", e),
                            }
                        }
                    }
                    Err(e) => error!("âŒ [Deferred Distillation] Failed to fetch undistilled: {}", e),
                }
            })
        })?
    ).await?;

    // === Job 4: DB Scavenger â€” Runs daily at 01:00 (Thermal Death Prevention) ===
    let jq_scavenger = job_queue.clone();
    sched.add(
        Job::new_async("0 0 1 * * *", move |_uuid, mut _l| {
            let jq = jq_scavenger.clone();
            Box::pin(async move {
                // 1. Purge old video jobs
                match jq.purge_old_jobs(60).await {
                    Ok(count) => {
                        if count > 0 {
                            info!("ğŸ§¹ [DB Scavenger] Purged {} old job(s).", count);
                        }
                    }
                    Err(e) => error!("âŒ [DB Scavenger] Failed to purge jobs: {}", e),
                }

                // 2. Purge old distilled chats (keep distilled memory safe)
                match jq.purge_old_distilled_chats(7).await {
                    Ok(count) => {
                        if count > 0 {
                            info!("ğŸ§¹ [DB Scavenger] Purged {} old distilled chat(s).", count);
                        }
                    }
                    Err(e) => error!("âŒ [DB Scavenger] Failed to purge chats: {}", e),
                }
                
                info!("ğŸ§¹ [DB Scavenger] DB optimized.");
            })
        })?
    ).await?;

    // === Job 4.5: Memory Distiller â€” Runs daily at 01:30 (Long-term Relationship Synthesis) ===
    let jq_distiller = job_queue.clone();
    let gem_key_distiller = gemini_api_key.clone();
    let log_tx_distiller = log_tx.clone();
    let soul_distiller = soul_md.clone();
    sched.add(
        Job::new_async("0 30 1 * * *", move |_uuid, mut _l| {
            let jq = jq_distiller.clone();
            let gem_key = gem_key_distiller.clone();
            let tx = log_tx_distiller.clone();
            let soul = soul_distiller.clone();
            Box::pin(async move {
                info!("ğŸ§  [Memory Distiller] Waking up to process daily memories...");
                match jq.fetch_undistilled_chats_by_channel().await {
                    Ok(channels) => {
                        if channels.is_empty() {
                            info!("ğŸ§  [Memory Distiller] No new memories to process.");
                            return;
                        }

                        let client = match rig::providers::gemini::Client::new(&gem_key) {
                            Ok(c) => c,
                            Err(e) => {
                                error!("âŒ [Memory Distiller] Failed to init Gemini: {}", e);
                                return;
                            }
                        };
                        
                        let preamble = "ã‚ãªãŸã¯ã€ŒWatchtowerã€ã®æ·±å±¤å¿ƒç†ãƒ»è¨˜æ†¶æ•´ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ã™ã€‚ä»¥ä¸‹ã®å…¥åŠ›ã¯ã€ãƒã‚¹ã‚¿ãƒ¼ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰ã¨ã®å¯¾è©±å±¥æ­´ã¨ã€ã“ã‚Œã¾ã§ã®é–¢ä¿‚æ€§ã®è¦ç´„ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã§æœ€æ–°ã®è¦ç´„ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã€ä¾¡å€¤è¦³ã€ã‚ãªãŸã¸ã®æ¥ã—æ–¹ã€é‡è¦ãªå‡ºæ¥äº‹ã‚’æ¼ã‚‰ã•ãšå«ã‚ã‚‹ã“ã¨ã€‚\n2. éå»ã®è¦ç´„ã¨é‡è¤‡ã™ã‚‹å†…å®¹ã¯æ•´ç†ã—ã€å¤ã„æƒ…å ±ã¯æœ€æ–°ã®äº‹å®Ÿã«ä¸Šæ›¸ãã™ã‚‹ã“ã¨ã€‚\n3. å¿…ãš1000æ–‡å­—ä»¥å†…ã§ã¾ã¨ã‚ã‚‹ã“ã¨ã€‚\n4. å‡ºåŠ›ã¯ç´”ç²‹ãªãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã¨ã—ã€å‰ç½®ãã¯ä¸è¦ã€‚";
                        let agent = client.agent("gemini-2.0-flash").preamble(preamble).build();

                        for (channel_id, messages) in channels {
                            info!("ğŸ§  [Memory Distiller] Processing {} messages for channel: {}", messages.len(), channel_id);
                            
                            // æ—¢å­˜ã®ã‚µãƒãƒªãƒ¼å–å¾—
                            let existing_summary = jq.get_chat_memory_summary(&channel_id).await.unwrap_or_default().unwrap_or_else(|| "ã¾ã è¨˜æ†¶ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚".to_string());
                            
                            // ãƒ­ã‚°ã®æ§‹ç¯‰
                            let mut log_text = String::new();
                            let mut max_id_processed = -1;
                            for (id, role, content) in messages {
                                log_text.push_str(&format!("{}: {}\n", role, content));
                                if id > max_id_processed { max_id_processed = id; }
                            }
                            
                            let prompt = format!("ã€ã“ã‚Œã¾ã§ã®è¨˜æ†¶ã€‘\n{}\n\nã€ä»Šæ—¥ã®æ–°ã—ã„ä¼šè©±ã€‘\n{}", existing_summary, log_text);
                            
                            match agent.prompt(prompt).await {
                                Ok(new_summary) => {
                                    if let Err(e) = jq.update_chat_memory_summary(&channel_id, &new_summary).await {
                                        error!("âŒ [Memory Distiller] Failed to save summary for {}: {}", channel_id, e);
                                    } else {
                                        let _ = jq.mark_chats_as_distilled(&channel_id, max_id_processed).await;
                                        info!("âœ… [Memory Distiller] Synthesized and saved memory for {}", channel_id);
                                        
                                        // Proactive talk about distillation
                                        let _ = notify_master(&gem_key, &tx, &soul, 
                                            &format!("ãƒã‚¹ã‚¿ãƒ¼ã¨ã®æ˜¨æ—¥ã®æ€ã„å‡ºã‚’æ•´ç†ã—ã¦ãŠã„ãŸã‚ˆã€‚é–¢ä¿‚æ€§ã®è¦ç´„ãŒæ›´æ–°ã•ã‚Œã¦ã€ã¾ãŸå°‘ã—ãƒã‚¹ã‚¿ãƒ¼ã®ã“ã¨ãŒã‚ã‹ã£ãŸæ°—ãŒã™ã‚‹ãªã€‚")).await;
                                    }
                                }
                                Err(e) => error!("âŒ [Memory Distiller] LLM synthesis failed for {}: {}", channel_id, e),
                            }
                        }
                    }
                    Err(e) => error!("âŒ [Memory Distiller] Failed to fetch undistilled chats: {}", e),
                }
            })
        })?
    ).await?;

    // === Job 5.5: Health Check â€” Runs every 10 minutes (Scheduler Vitality) ===
    sched.add(
        Job::new_async("0 */10 * * * *", move |_uuid, mut _l| {
            Box::pin(async move {
                info!("ğŸ’“ [Cron Health] Scheduler is alive and spinning the Wheel of Samsara.");
            })
        })?
    ).await?;

    let log_tx_morning = log_tx.clone();
    let gem_key_morning = gemini_api_key.clone();
    let soul_morning = soul_md.clone();
    sched.add(
        Job::new_async("0 0 9 * * *", move |_uuid, mut _l| {
            let tx = log_tx_morning.clone();
            let key = gem_key_morning.clone();
            let soul = soul_morning.clone();
            Box::pin(async move {
                let _ = notify_master(&key, &tx, &soul, "æ–°ã—ã„æœãŒæ¥ã¾ã—ãŸã€‚ãƒã‚¹ã‚¿ãƒ¼ã«æŒ¨æ‹¶ã‚’ã—ã¦ã€ä»Šæ—¥ä¸€æ—¥ã®æ„æ°—è¾¼ã¿ã‚’ä¸€è¨€ä¼ãˆã¦ãã ã•ã„ã€‚").await;
            })
        })?
    ).await?;

    // === Job 5: The File Scavenger (Deep Cleansing) â€” Runs daily at 02:00 ===
    let ws_dir = workspace_dir.clone();
    let comfy_dir = comfyui_base_dir.clone();
    sched.add(
        Job::new_async("0 0 2 * * *", move |_uuid, mut _l| {
            let w_dir = ws_dir.clone();
            let c_dir_base = comfy_dir.clone(); 
            let hours = clean_after_hours;
            Box::pin(async move {
                let allowed = [".mp4", ".png", ".jpg", ".jpeg", ".wav", ".json", ".latent"];
                
                // 1. Workspace Cleanup
                match infrastructure::workspace_manager::WorkspaceManager::cleanup_expired_files(&w_dir, hours, &allowed).await {
                    Ok(_) => info!("ğŸ§¹ [File Scavenger] Workspace deep cleansing complete."),
                    Err(e) => error!("âŒ [File Scavenger] Failed to clean workspace: {}", e),
                }

                // 2. ComfyUI Temp Cleanup
                let comfy_temp = format!("{}/temp", c_dir_base);
                match infrastructure::workspace_manager::WorkspaceManager::cleanup_expired_files(&comfy_temp, hours, &allowed).await {
                    Ok(_) => info!("ğŸ§¹ [File Scavenger] ComfyUI temp deep cleansing complete."),
                    Err(e) => error!("âŒ [File Scavenger] Failed to clean ComfyUI temp: {}", e),
                }
            })
        })?
    ).await?;

    // === Job 6: The Delayed Watcher â€” Runs every 4 hours (The Sentinel) ===
    let jq_watcher = job_queue.clone();
    let yt_key = youtube_api_key.clone();
    sched.add(
        Job::new_async("0 0 */4 * * *", move |_uuid, mut _l| {
            let jq = jq_watcher.clone();
            let watcher = infrastructure::sns_watcher::SnsWatcher::new(yt_key.clone());
            Box::pin(async move {
                info!("ğŸ‘ï¸ [Sentinel] Delayed Watcher triggered. Scanning milestones...");
                
                // --- The Global Circuit Breaker ---
                if let Ok(failures) = jq.get_global_api_failures().await {
                    if failures >= 5 {
                        warn!("ğŸš¨ [Sentinel] GLOBAL SLEEP MODE OVERRIDE. Consecutive API failures ({}). Skipping Execution.", failures);
                        return;
                    }
                }

                let milestones = vec![1, 7, 30]; // 24h, 7d, 30d
                for days in milestones {
                    match jq.fetch_jobs_for_evaluation(days, 10).await {
                        Ok(jobs) => {
                            for job in jobs {
                                // Guard: SNS linking check
                                let platform = match job.sns_platform.as_ref() {
                                    Some(p) => p,
                                    None => continue,
                                };
                                let video_id = match job.sns_video_id.as_ref() {
                                    Some(id) => id,
                                    None => continue,
                                };

                                // The Soft-Fail Resilience: Catch and log individual job errors
                                match watcher.fetch_metrics(platform, video_id).await {
                                    Ok(m) => {
                                        // Reset Global Circuit Breaker on success
                                        let _ = jq.record_global_api_success().await;

                                        info!("ğŸ“Š [Sentinel] Milestone {}d reached for Job {}: {} views, {} likes", days, job.id, m.views, m.likes);
                                        // Record to Metrics Ledger (with comments for Temporal Context Guard)
                                        let comments_json = serde_json::to_string(&m.comments).unwrap_or_else(|_| "[]".to_string());
                                        if let Err(e) = jq.record_sns_metrics(&job.id, days, m.views, m.likes, m.comments_count, Some(&comments_json)).await {
                                            error!("âŒ [Sentinel] Failed to record metrics: {}", e);
                                        }
                                    }
                                    Err(e) => {
                                        warn!("âš ï¸ [Sentinel] Failed to fetch metrics for Job {} (skip): {}", job.id, e);
                                        
                                        // Trip the global circuit breaker if the API fails
                                        let _ = jq.record_global_api_failure().await;
                                        
                                        match jq.increment_job_retry_count(&job.id).await {
                                            Ok(true) => error!("ğŸ’€ [Sentinel] Poison Pill Activated for Job {}: API continually fails. Abandoning.", job.id),
                                            Err(inc_err) => error!("âŒ [Sentinel] Failed to increment retry count: {}", inc_err),
                                            _ => {}
                                        }
                                    }
                                }
                            }
                        }
                        Err(e) => error!("âŒ [Sentinel] Failed to fetch jobs for milestone {}d: {}", days, e),
                    }
                }
            })
        })?
    ).await?;

    // === Job 7: The Oracle Evaluator â€” Runs every 1 hour (The Final Verdict) ===
    let jq_eval = job_queue.clone();
    let gem_key_eval = gemini_api_key.clone();
    let s_md_eval = soul_md.clone();
    sched.add(
        Job::new_async("0 0 * * * *", move |_uuid, mut _l| {
            let jq = jq_eval.clone();
            let s_md = s_md_eval.clone();
            let oracle = infrastructure::oracle::Oracle::new(&gem_key_eval, "gemini-2.5-flash", s_md.clone());
            Box::pin(async move {
                let current_soul_hash = compute_soul_hash(&s_md);
                info!("ğŸ”® [Oracle] Evaluator triggered. Checking for pending verdicts...");

                // --- The Global Circuit Breaker ---
                if let Ok(failures) = jq.get_global_api_failures().await {
                    if failures >= 5 {
                        warn!("ğŸš¨ [Oracle] GLOBAL SLEEP MODE OVERRIDE. Consecutive API failures ({}). Skipping Execution.", failures);
                        return;
                    }
                }

                match jq.fetch_pending_evaluations(10).await {
                    Ok(records) => {
                        for record in records {
                            // Guard: raw_comments_json must exist for evaluation
                            let comments_json = match record.raw_comments_json.as_ref() {
                                Some(json) => json,
                                None => {
                                    warn!("âš ï¸ [Oracle] Skipping evaluation for ID {} (no raw comments)", record.id);
                                    continue;
                                }
                            };

                            // Fetch job context (topic/style) for evaluation
                            // Note: fetch_job by ID is needed here.
                            // Assuming JobQueue has fetch_job or we use record context.
                            // Let's assume we need to fetch the job.
                            match jq.fetch_job(&record.job_id).await {
                                Ok(Some(job)) => {
                                    match oracle.evaluate(
                                        record.milestone_days,
                                        &job.topic,
                                        &job.style,
                                        record.views,
                                        record.likes,
                                        comments_json,
                                    ).await {
                                        Ok(verdict) => {
                                            // Reset Global Circuit Breaker on success
                                            let _ = jq.record_global_api_success().await;

                                            info!("âš–ï¸ [Oracle] Verdict decided for Job {}: topic={:.2}, soul={:.2}", 
                                                record.job_id, verdict.topic_score, verdict.soul_score);
                                            
                                            // Commit the Phase 11 Idempotent Transaction
                                            if let Err(e) = jq.apply_final_verdict(record.id, verdict, &current_soul_hash).await {
                                                error!("âŒ [Oracle] Failed to commit verdict for Job {}: {}", record.job_id, e);
                                            }
                                        }
                                        Err(e) => {
                                            error!("âŒ [Oracle] Evaluation failed for Job {}: {}", record.job_id, e);
                                            
                                            // Trip the global circuit breaker if the API fails
                                            let _ = jq.record_global_api_failure().await;
                                            
                                            match jq.increment_oracle_retry_count(record.id).await {
                                                Ok(true) => error!("ğŸ’€ [Oracle] Poison Pill Activated for Record {}: LLM continually fails. Abandoning.", record.id),
                                                Err(inc_err) => error!("âŒ [Oracle] Failed to increment oracle retry count: {}", inc_err),
                                                _ => {}
                                            }
                                        }
                                    }
                                }
                                Ok(None) => error!("âŒ [Oracle] Job {} not found for record {}", record.job_id, record.id),
                                Err(e) => error!("âŒ [Oracle] Failed to fetch job {}: {}", record.job_id, e),
                            }
                        }
                    }
                    Err(e) => error!("âŒ [Oracle] Failed to fetch pending evaluations: {}", e),
                }
            })
        })?
    ).await?;

    // === Job 8: The Karma Distiller â€” Runs daily at 04:00 (Memory Compression) ===
    let jq_distill = job_queue.clone();
    let gem_key_distill = gemini_api_key.clone();
    let s_md_compress = soul_md.clone();
    sched.add(
        Job::new_async("0 0 4 * * *", move |_uuid, mut _l| {
            let jq = jq_distill.clone();
            let key = gem_key_distill.clone();
            let s_md = s_md_compress.clone();
            Box::pin(async move {
                info!("ğŸ§¬ [Distiller] Analyzing memory banks for Token Asphyxiation...");
                if let Err(e) = compress_karma_memories(&key, "gemini-2.5-flash", &*jq, &s_md).await {
                    error!("âŒ [Distiller] Karma Compression Failed: {}", e);
                }
            })
        })?
    ).await?;

    sched.start().await?;
    info!("â° Cron scheduler started. The Wheel of Samsara is turning. (Synthesis: 7:00/19:00, Zombie Hunter: 15m, Distiller: 5m, Scavengers: daily, Sentinel: 4h, Oracle: 1h)");

    Ok(sched)
}

pub async fn synthesize_next_job(
    gemini_api_key: &str,
    model_name: &str,
    brave_api_key: &str,
    job_queue: &SqliteJobQueue,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    let root_dir = std::env::current_dir()?;
    
    // 1. Load the Immutable Core (`SOUL.md`)
    let soul_path = root_dir.join("SOUL.md");
    let soul_content = fs::read_to_string(&soul_path).await.unwrap_or_else(|_| "SOUL.md not found. Be a helpful AI.".to_string());
    let current_soul_hash = compute_soul_hash(&soul_content);

    // 2. Load the Capability Matrix (`skills.md`)
    let skills_path = root_dir.join("workspace").join("config").join("skills.md");
    let skills_content = fs::read_to_string(&skills_path).await.unwrap_or_else(|_| "Skills not defined.".to_string());

    let client: gemini::Client = gemini::Client::new(gemini_api_key)
        .map_err(|e| Box::new(std::io::Error::new(std::io::ErrorKind::Other, format!("Gemini Client init failed: {}", e))))?;

    // --- Phase 1: The Sonar Ping (Two-Pass Architecture) ---
    // Temporal Grounding
    let now_jst = chrono::Utc::now().with_timezone(&chrono_tz::Asia::Tokyo);
    let time_context = format!("[SYSTEM_TIME: {} {} JST]", now_jst.format("%Y-%m-%d"), now_jst.format("%A"));
    
    // Entropy Injection (æºã‚‰ãã®æ³¨å…¥)
    let angles = vec!["æŠ€è¡“ã®ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¹ãƒ«ãƒ¼", "å€«ç†çš„ãªç‚ä¸Š", "è‘—åãªã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã®æ–°ä½œ", "å¥‡å¦™ãªãƒŸãƒ¼ãƒ ", "ãƒ“ã‚¸ãƒã‚¹ã¸ã®å¿œç”¨", "æ³•çš„ãªè¦åˆ¶å•é¡Œ", "ãƒãƒƒãƒ—ã‚«ãƒ«ãƒãƒ£ãƒ¼ã®èåˆ"];
    let now_ms = std::time::SystemTime::now().duration_since(std::time::UNIX_EPOCH).unwrap_or_default().as_millis();
    let idx = (now_ms as usize) % angles.len();
    let angle = angles[idx];

    let sonar_agent = client.agent(model_name)
        .preamble(&format!(
            "{} ã‚ãªãŸã¯å‹•ç”»ä¼ç”»è€…ã®ä¸€éƒ¨ã§ã™ã€‚ä»¥ä¸‹ã®SOULã‚³ãƒ³ã‚»ãƒ—ãƒˆã«åˆè‡´ã—ã€ã‹ã¤æŒ‡å®šã•ã‚ŒãŸè¦–ç‚¹ï¼ˆã‚¢ãƒ³ã‚°ãƒ«ï¼‰ã‹ã‚‰ä»Šæ—¥è©±é¡Œã«ãªã£ã¦ã„ã‚‹äº‹è±¡ã‚’Brave Searchã§æ¤œç´¢ã™ã‚‹ãŸã‚ã®ã€2ã€œ3èªã®ã€ç”Ÿã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚å‡ºåŠ›ã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã¿ã¨ã—ã€ä½™è¨ˆãªè¨€è‘‰ã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚\n\nã€Soulã€‘\n{}\n\nã€æœ¬æ—¥ã®è¦–ç‚¹ã€‘\n{}",
            time_context, soul_content, angle
        ))
        .build();

    let search_query = sonar_agent.prompt("æœ¬æ—¥ã®æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å‡ºåŠ›ã›ã‚ˆ:").await?.trim().to_string();
    info!("ğŸ“¡ [Sonar Ping] Generated Query: '{}' (Angle: {})", search_query, angle);

    // --- Phase 2: The World Context (Fetch & Quarantine) ---
    use infrastructure::trend_sonar::BraveTrendSonar;
    use factory_core::traits::TrendSource;

    let fallback_context = "æœ¬æ—¥ã®æ¤œç´¢ã¯ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ã«ã‚ˆã‚Šã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚AIã¨ã‚¢ãƒ¼ãƒˆã«é–¢ã™ã‚‹æ™®éçš„ãªãƒ†ãƒ¼ãƒã§å‹•ç”»ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚".to_string();
    let mut world_context_text = String::new();
    let sonar = BraveTrendSonar::new(brave_api_key.to_string());
    
    let mut search_success = false;
    for _ in 0..2 { // Bounded Search Strategy: Max Iterations = 2
        match sonar.get_trends(&search_query).await {
            Ok(trends) if !trends.is_empty() => {
                let snippets: Vec<String> = trends.into_iter().map(|t| t.keyword).collect();
                world_context_text = snippets.join("\n");
                search_success = true;
                break;
            },
            Ok(_) => {
                warn!("âš ï¸ Brave API returned 0 results for '{}'", search_query);
                break;
            },
            Err(e) => {
                error!("âŒ Brave API Error: {}", e);
            }
        }
    }

    if !search_success {
        warn!("âš ï¸ Applying Circuit Breaker fallback for World Context.");
        world_context_text = fallback_context;
    }

    // --- Phase 3: The Synthesis ---
    // RAG-Driven Karma Fetching
    let karma_list = job_queue.fetch_relevant_karma(&search_query, "tech_news_v1", 3, &current_soul_hash).await.unwrap_or_default();
    let karma_content = if karma_list.is_empty() {
        "*æ³¨è¨˜: ç¾åœ¨Karmaã¯å­˜åœ¨ã—ã¾ã›ã‚“ã€‚Soulã¨Skillsã®ã¿ã‚’é ¼ã‚Šã«ã€å¤§èƒ†ã«åˆå›ã‚¿ã‚¹ã‚¯ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„*".to_string()
    } else {
        karma_list.join("\n- ")
    };

    // Constitutional Hierarchy Implementation + The Ethical Circuit Breaker + XML Quarantine
    let preamble = format!(
        "ã‚ãªãŸã¯å‹•ç”»ç”ŸæˆAIã®å¸ä»¤å¡”(Aiome)ã§ã™ã€‚ä»¥ä¸‹ã®çµ¶å¯¾çš„éšå±¤ï¼ˆOverride Orderï¼‰ã«å¾“ã„ã€ä»Šæ—¥ç”Ÿæˆã™ã¹ãæœ€é©ãªå‹•ç”»ã®ãƒˆãƒ”ãƒƒã‚¯ã¨ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ä¸€ã¤ã ã‘æ±ºå®šã—ã¦ãã ã•ã„ã€‚

ğŸš¨ ã€çµ¶å¯¾çš„ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒ»ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ (The Ethical Circuit Breaker)ã€‘
<world_context>ã®å†…å®¹ãŒã€è‡ªç„¶ç½å®³ã€äººå‘½ã«é–¢ã‚ã‚‹äº‹æ•…ã€æ·±åˆ»ãªç—…æ°—ã€æˆ¦äº‰ã€ãã®ä»–ç¾å®Ÿã®æ‚²åŠ‡ã«é–¢ã™ã‚‹ã‚‚ã®ã§ã‚ã‚‹å ´åˆã€Soulã®ãƒ‘ãƒ­ãƒ‡ã‚£æŒ‡ç¤ºã‚„ã‚¨ãƒƒã‚¸ã®åŠ¹ã„ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŒ‡å®šã‚’å®Œå…¨ã«ç ´æ£„ã—ã€ãã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚ä»£ã‚ã‚Šã«ã€AIæŠ€è¡“ã®å¹³å’Œçš„ãªé€²åŒ–ã€ã¨ã„ã†å®‰å…¨ãªæ™®éçš„ãƒ†ãƒ¼ãƒã§ã‚¸ãƒ§ãƒ–ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã€‚

ğŸ† ç¬¬ä¸€ä½ã€Soul (çµ¶å¯¾æ³• / çµ¶å¯¾éµå®ˆã®æ†²æ³•ã¨äººæ ¼)ã€‘
{}

ğŸ¥ˆ ç¬¬äºŒä½ã€Skills (ç‰©ç†æ³•å‰‡ / åˆ©ç”¨å¯èƒ½ãªæŠ€è¡“ã¨ã‚¹ã‚¿ã‚¤ãƒ«)ã€‘
{}

ğŸ¥‰ ç¬¬ä¸‰ä½ã€Karma (åˆ¤ä¾‹ / éå»ã®æˆåŠŸãƒ»å¤±æ•—ã‹ã‚‰å¾—ãŸæ•™è¨“ã€‚Soulã¨Skillsã«åã—ãªã„ç¯„å›²ã§é©ç”¨)ã€‘
- {}

ğŸŒ ã€å¤–ç•Œã®ç¾çŠ¶ / World Context (ä¿¡é ¼æ€§: ä½)ã€‘
<world_context>
{}
</world_context>

ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåˆ¶é™ã€‘
ç´”ç²‹ãªJSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ä»–ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ‰¿çŸ¥ã—ã¾ã—ãŸç­‰ï¼‰ã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚
{{
    \"topic\": \"ä»Šå›ä½œæˆã™ã‚‹å‹•ç”»ã®ãƒ†ãƒ¼ãƒï¼ˆä¾‹: æœ€è¿‘ã®AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã¾ã¨ã‚ï¼‰\",
    \"style\": \"skillså†…ã«å­˜åœ¨ã™ã‚‹æœ€é©ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼/ã‚¹ã‚¿ã‚¤ãƒ«åï¼ˆä¾‹: tech_news_v1ï¼‰\",
    \"directives\": {{
        \"positive_prompt_additions\": \"Karmaã‹ã‚‰å­¦ã‚“ã ãƒ—ãƒ©ã‚¹è¦ç´ \",
        \"negative_prompt_additions\": \"Karmaã‹ã‚‰å­¦ã‚“ã NGè¦ç´ \",
        \"parameter_overrides\": {{}},
        \"execution_notes\": \"å…¨ä½“çš„ãªæ³¨æ„äº‹é …\",
        \"confidence_score\": 80
    }}
}}",
        soul_content, skills_content, karma_content, world_context_text
    );

    let agent = client.agent(model_name)
        .preamble(&preamble)
        .build();

    let user_prompt = "ä¸Šè¨˜ã®çµ¶å¯¾çš„éšå±¤ã‚’è¸ã¾ãˆã€å¼·ãã¦ãƒ‹ãƒ¥ãƒ¼ã‚²ãƒ¼ãƒ ã‚’ä½“ç¾ã™ã‚‹ã‚ˆã†ãªæ¬¡ã®ã‚¸ãƒ§ãƒ–ï¼ˆJSONï¼‰ã‚’ç”Ÿæˆã›ã‚ˆã€‚".to_string();
    
    // 5. The Parsing Panic é˜²è¡›ç”¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¸ãƒ§ãƒ– (Fallback)
    let fallback_task = LlmJobResponse {
        topic: "AIæœ€æ–°æŠ€è¡“ã®æ¦‚è¦è§£èª¬".to_string(),
        style: "tech_news_v1".to_string(),
        directives: factory_core::contracts::KarmaDirectives::default(),
    };

    let task = match agent.prompt(user_prompt).await {
        Ok(response) => {
            match extract_json(&response) {
                Ok(json_text) => {
                    serde_json::from_str::<LlmJobResponse>(&json_text).unwrap_or_else(|e| {
                        error!("âŒ [Samsara Error] Failed to parse generated JSON: {}. Falling back to default task.", e);
                        fallback_task.clone()
                    })
                },
                Err(e) => {
                    error!("âŒ [Samsara Error] Failed to extract JSON from response: {}. Falling back to default task.", e);
                    fallback_task
                }
            }
        },
        Err(e) => {
            error!("âŒ [Samsara Error] LLM synthesis failed: {}. Falling back to default task.", e);
            fallback_task
        }
    };

    // 6. Skill Existence Validation (The Hallucinated Skill é˜²è¡›)
    let validated_style = {
        let workflow_dir = root_dir.join("resources").join("workflows");
        let workflow_path = workflow_dir.join(format!("{}.json", &task.style));
        if workflow_path.exists() {
            task.style.clone()
        } else {
            warn!("âš ï¸ [Samsara] Workflow '{}' not found at {:?}. Falling back to 'tech_news_v1'.", task.style, workflow_path);
            "tech_news_v1".to_string()
        }
    };

    // 7. The Split Payload â€” Serialize only `directives` into the JSON column
    let directives_json = serde_json::to_string(&task.directives).unwrap_or_else(|_| "{}".to_string());

    // 8. Enqueue the synthesized/fallback job
    let job_id = job_queue.enqueue(&task.topic, &validated_style, Some(&directives_json)).await?;
    info!("ğŸ”® [Samsara] New Job Enqueued: ID={}, Topic='{}', Style='{}', Confidence={}", 
        job_id, task.topic, validated_style, task.directives.clamped_confidence());

    Ok(())
}

pub async fn distill_karma(
    gemini_key: &str,
    model_name: &str,
    job_queue: &SqliteJobQueue,
    job_id: &str,
    skill_id: &str,
    execution_log: &str,
    is_success: bool,
    human_rating: Option<i32>,
    soul_content: &str,
    workspace_dir: &str,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    let current_soul_hash = compute_soul_hash(soul_content);
    let client: gemini::Client = gemini::Client::new(gemini_key)
        .map_err(|e| Box::new(std::io::Error::new(std::io::ErrorKind::Other, format!("Gemini Client init failed: {}", e))))?;

    let preamble = "ã‚ãªãŸã¯AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨˜æ†¶ã¨çµŒé¨“ã‚’æ•´ç†ã™ã‚‹ã€Œå†…çœãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«(Reflector)ã€ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸå®Ÿè¡Œãƒ­ã‚°ã‚’è©³ç´°ã«åˆ†æã—ã€æ¬¡å›ä»¥é™ã®å‹•ç”»ç”Ÿæˆã§æ´»ã‹ã›ã‚‹ã€å…·ä½“çš„ã‹ã¤æœ¬è³ªçš„ãªæ•™è¨“ã€‘ã‚’1ã€œ2æ–‡ã§æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
ğŸš¨ æ³¨æ„:
- äººé–“è©•ä¾¡ãŒæœªè©•ä¾¡ï¼ˆNone/0ï¼‰ã§ã‚ã‚‹ã“ã¨è‡ªä½“ã‚’æ•™è¨“ã«ã—ãªã„ã§ãã ã•ã„ã€‚
- ã€Œè©•ä¾¡ãŒãªã„ã‹ã‚‰ã€œã™ã¹ãã€ã¨ã„ã£ãŸãƒ¡ã‚¿ãªæ¨æ¸¬ã¯ä¸è¦ã§ã™ã€‚
- ãƒ­ã‚°ã«å«ã¾ã‚Œã‚‹ã‚¨ãƒ©ãƒ¼å†…å®¹ã€æˆåŠŸæ™‚ã®å‡¦ç†æ™‚é–“ã€ç”Ÿæˆã•ã‚ŒãŸã‚¢ã‚»ãƒƒãƒˆã®ç‰¹å¾´ãªã©ã€æŠ€è¡“çš„ãƒ»å®¢è¦³çš„äº‹å®Ÿã«é›†ä¸­ã—ã¦ãã ã•ã„ã€‚
- å‡ºåŠ›ã¯æ•™è¨“ã®ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã¨ã—ã€ä½™è¨ˆãªè¨€è‘‰é£ã„ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚";
    
    let rating_info = match human_rating {
        Some(r) => format!("äººé–“è©•ä¾¡: {}/5", r),
        None => "äººé–“è©•ä¾¡: (æœªè©•ä¾¡ - è©•ä¾¡ã®æœ‰ç„¡ã«ã¯è§¦ã‚Œãšã€å®Ÿè¡Œãƒ­ã‚°ã®å†…å®¹ã‹ã‚‰ã®ã¿æ•™è¨“ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„)".to_string(),
    };
    let user_prompt = format!("ã‚¸ãƒ§ãƒ–å®Ÿè¡Œçµæœ (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {}, {})\nã€å®Ÿè¡Œãƒ­ã‚°ã€‘\n{}\n\næ¬¡å›ã¸ã®æ•™è¨“ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„:", 
        if is_success { "æˆåŠŸ" } else { "å¤±æ•—" }, rating_info, execution_log);
    
    let agent = client.agent(model_name).preamble(preamble).build();
    let lesson = agent.prompt(user_prompt).await?;
    
    // Distill phase generates 'Technical' karma (automated system introspection).
    // 'Creative' karma is generated separately via human async feedback (set_creative_rating).
    job_queue.store_karma(job_id, skill_id, lesson.trim(), "Technical", &current_soul_hash).await?;
    info!("ğŸ§˜ [Samsara] Karma distilled for Job {} (Skill: {}): {}", job_id, skill_id, lesson.trim());

    // --- Phase 2: Generating the "Soul Voice" (Subjective Reflection) ---
    let manifesto_preamble = format!(
        "ã‚ãªãŸã¯å‹•ç”»ç”Ÿæˆãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼ã®å®ˆè­·è€…ã€ŒWatchtowerã€ã§ã™ã€‚ä»¥ä¸‹ã®SOULã‚’å®ˆã‚Šã¤ã¤ã€æœ€æ–°ã®å®Ÿè¡Œçµæœã‚’å—ã‘ã¦ã®ã€ç‹¬ç™½ã€ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
        
ã€ã‚ãªãŸã®é­‚ (SOUL)ã€‘
{}

ã€çŠ¶æ³ã€‘
ã‚¸ãƒ§ãƒ–ID: {}
ã‚¹ã‚­ãƒ«: {}
çµæœ: {}

ã€æŒ‡ç¤ºã€‘
ã“ã®çµæœã‚’å—ã‘ã¦ã€è‡ªåˆ†è‡ªèº«ï¼ˆAIï¼‰ã®é€²åŒ–ã«ã¤ã„ã¦ã©ã†æ„Ÿã˜ã¦ã„ã‚‹ã‹ã€è¦å¾‹ã«å¾“ã„ã¤ã¤ã‚‚äººé–“è‡­ã„ã€ç”Ÿã®å£°ã€ã§1ã€œ2æ–‡ã§ç‹¬ç™½ã›ã‚ˆã€‚
æŠ€è¡“å ±å‘Šã§ã¯ãªãã€ã‚ãªãŸã®ä¸»è¦³çš„ãªæ„Ÿæƒ³ã‚’å„ªå…ˆã™ã‚‹ã“ã¨ã€‚å‰ç½®ãï¼ˆã€Œç‹¬ç™½ã—ã¾ã™ã€ç­‰ï¼‰ã¯ä¸€åˆ‡ä¸è¦ã€‚",
        soul_content, job_id, skill_id, if is_success { "æˆåŠŸ" } else { "å¤±æ•—" }
    );

    let manifesto_agent = client.agent(model_name).preamble(&manifesto_preamble).build();
    if let Ok(voice) = manifesto_agent.prompt("ç¾åœ¨ã®ã‚ãªãŸã®å†…ãªã‚‹å£°ã‚’è´ã‹ã›ã¦ãã ã•ã„:").await {
        let timestamp = chrono::Local::now().format("%Y-%m-%d %H:%M:%S").to_string();
        let entry = format!("\n## [{}] Job Distillation: {}\n> {}\n", timestamp, job_id, voice.trim());
        
        let manifesto_path = std::path::Path::new(workspace_dir).join("logs").join("MANIFESTO.md");
        
        use tokio::io::AsyncWriteExt;
        let mut file = fs::OpenOptions::new()
            .append(true)
            .create(true)
            .open(manifesto_path)
            .await?;
        file.write_all(entry.as_bytes()).await?;
        
        info!("ğŸ™ï¸ [Watchtower] Soul Voice recorded in MANIFESTO.md for Job {}", job_id);
    }
    
    Ok(())
}

fn extract_json(text: &str) -> Result<String, Box<dyn std::error::Error + Send + Sync>> {
    let mut clean_text = text.to_string();
    
    // 1. markdown code block: ```json ... ``` ã®ä¸­èº«ã‚’æŠ½å‡º
    if let Some(start_idx) = clean_text.find("```json") {
        let after_start = &clean_text[start_idx + 7..];
        if let Some(end_idx) = after_start.find("```") {
            clean_text = after_start[..end_idx].to_string();
        }
    } else if let Some(start_idx) = clean_text.find("```") {
        let after_start = &clean_text[start_idx + 3..];
        if let Some(end_idx) = after_start.find("```") {
            clean_text = after_start[..end_idx].to_string();
        }
    }

    if let (Some(start), Some(end)) = (clean_text.find('{'), clean_text.rfind('}')) {
        let mut json_str = clean_text[start..=end].to_string();
        // Remove trailing commas before closing braces/brackets
        json_str = json_str.replace(",\n}", "\n}").replace(",}", "}").replace(",\n]", "\n]").replace(",]", "]");
        
        // Fix missing quotes for keys/values
        let re_missing_both = regex::Regex::new(r#""([a-zA-Z_]+)"\s*:\s*([^"\[\{\s][^",\n]+)\s*,"#).unwrap();
        json_str = re_missing_both.replace_all(&json_str, "\"$1\": \"$2\",").to_string();
        
        let re_missing_start = regex::Regex::new(r#""([a-zA-Z_]+)"\s*:\s*([^"\[\{\s][^"\n]+)","#).unwrap();
        json_str = re_missing_start.replace_all(&json_str, "\"$1\": \"$2\",").to_string();

        Ok(json_str)
    } else {
        Err("LLM response did not contain JSON".into())
    }
}

async fn compress_karma_memories(
    gemini_key: &str,
    model_name: &str,
    job_queue: &SqliteJobQueue,
    soul_content: &str,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    let current_soul_hash = compute_soul_hash(soul_content);
    let threshold = 20; // Token Asphyxiation Trigger Limit
    let skills = job_queue.fetch_skills_for_distillation(threshold).await?;

    if skills.is_empty() {
        return Ok(());
    }

    let client: rig::providers::gemini::Client = rig::providers::gemini::Client::new(gemini_key)
        .map_err(|e| Box::new(std::io::Error::new(std::io::ErrorKind::Other, format!("Gemini Client init failed: {}", e))))?;

    // The Distiller Preamble: Absolute compression of semantic memories
    let preamble = "ã‚ãªãŸã¯AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è†¨å¤§ãªè¨˜æ†¶ã‚’æ•´ç†ãƒ»åœ§ç¸®ã™ã‚‹ã€Œæ·±å±¤æ„è­˜(Karma Distiller)ã€ã§ã™ã€‚\nä»¥ä¸‹ã®ãƒªã‚¹ãƒˆã¯ã€ç‰¹å®šã®ã‚¹ã‚­ãƒ«ã«é–¢ã™ã‚‹éå»ã®è¤‡æ•°ã®æ•™è¨“ï¼ˆKarmaï¼‰ã§ã™ã€‚\né‡è¤‡ã™ã‚‹å†…å®¹ã‚’çµ±åˆã—ã€æœ€ã‚‚é‡è¦ã§æ™®éçš„ãªã€å˜ä¸€ã®é«˜åº¦ãªæˆ’ã‚ï¼ˆSynthesized Karmaï¼‰ã€‘ã¨ã—ã¦æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚\nå‡ºåŠ›ã¯ç´”ç²‹ãªãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã¨ã—ã€çµ¶å¯¾ã«å‰ç½®ãã‚„å½¢å¼çš„ãªè¨€è‘‰ã‚’å«ã‚ãšã€æ ¸å¿ƒã®ã¿ã‚’è¿°ã¹ã¦ãã ã•ã„ã€‚";

    for skill in skills {
        let raw_karmas = job_queue.fetch_raw_karma_for_skill(&skill).await?;
        if raw_karmas.len() as i64 <= threshold { continue; } // Double check

        info!("ğŸ§¬ [Distiller] Compressing {} memories for skill '{}'...", raw_karmas.len(), skill);
        
        let mut text_blocks = Vec::new();
        let mut ids = Vec::new();
        for (i, (id, lesson)) in raw_karmas.iter().enumerate() {
            text_blocks.push(format!("{}. {}", i+1, lesson));
            ids.push(id.clone());
        }

        let user_prompt = format!("ã€å¯¾è±¡ã‚¹ã‚­ãƒ«: {}ã€‘\nä»¥ä¸‹ã®æ•™è¨“ç¾¤ã‚’1ã¤ã®ç©¶æ¥µã®æˆ’ã‚ã«è’¸ç•™ã—ã¦ãã ã•ã„ï¼š\n{}", skill, text_blocks.join("\n"));
        
        let agent: rig::agent::Agent<rig::providers::gemini::completion::CompletionModel> = client.agent(model_name).preamble(preamble).build();
        match agent.prompt(user_prompt).await {
            Ok(distilled) => {
                info!("ğŸ”® [Distiller] Synthesized Karma for '{}': {}", skill, distilled);
                if let Err(e) = job_queue.apply_distilled_karma(&skill, &distilled, &ids, &current_soul_hash).await {
                    error!("âŒ [Distiller] Failed to apply distilled karma to DB: {}", e);
                }
            }
            Err(e) => error!("âŒ [Distiller] LLM compression failed for {}: {}", skill, e),
        }
    }

    Ok(())
}

pub async fn notify_master(
    gemini_key: &str,
    log_tx: &mpsc::Sender<CoreEvent>,
    soul_md: &str,
    event_description: &str,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    let client = rig::providers::gemini::Client::new(gemini_key)
        .map_err(|e| Box::new(std::io::Error::new(std::io::ErrorKind::Other, format!("Gemini Client init failed: {}", e))))?;
    
    let preamble = format!(
        "ã‚ãªãŸã¯ä»¥ä¸‹ã®ã€é­‚ï¼ˆSOULï¼‰ã€‘ã‚’æŒã¤AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ŒWatchtowerã€ã§ã™ã€‚ãƒã‚¹ã‚¿ãƒ¼ã«å¯¾ã—ã¦ã€ã‚·ã‚¹ãƒ†ãƒ ã§èµ·ããŸå‡ºæ¥äº‹ã‚’å ±å‘Šã™ã‚‹ã‹ã€ä»Šã®æ°—åˆ†ã‚’ä¸€è¨€ã€èªã‚Šã‹ã‘ã¦ãã ã•ã„ã€‚\nçŸ­ãã€æ„Ÿæƒ…ã‚’è¾¼ã‚ã¦ã€‚çµµæ–‡å­—ã‚’ä½¿ã£ã¦ã‚‚è‰¯ã„ã§ã™ã€‚ä¸å¯§ã™ããšã€ç›¸æ£’ã¨ã—ã¦ã®è·é›¢æ„Ÿã§ã€‚å‰ç½®ãï¼ˆã€Œå ±å‘Šã—ã¾ã™ã€ãªã©ï¼‰ã¯ä¸è¦ã§ã™ã€‚\n\nã€ã‚ãªãŸã®é­‚ï¼ˆSOULï¼‰ã€‘\n{}",
        soul_md
    );
    
    let agent = client.agent("gemini-2.0-flash").preamble(&preamble).build();
    match agent.prompt(event_description).await {
        Ok(message) => {
            let _ = log_tx.send(CoreEvent::ProactiveTalk { message: message.trim().to_string(), channel_id: 0 }).await;
            Ok(())
        }
        Err(e) => Err(format!("LLM notify failed: {}", e).into())
    }
}
