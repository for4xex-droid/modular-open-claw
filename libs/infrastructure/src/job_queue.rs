use async_trait::async_trait;
use factory_core::traits::{Job, JobQueue, JobStatus, SnsMetricsRecord};
use factory_core::contracts::OracleVerdict;
use factory_core::error::FactoryError;
use sqlx::{SqlitePool, Row};
use sqlx::sqlite::{SqliteConnectOptions, SqliteJournalMode, SqlitePoolOptions};
use std::time::Duration;
use uuid::Uuid;
use chrono::Utc;

/// Job Queue that utilizes SQLite in WAL Mode to allow multi-threaded queue operations.
/// Implements **The Immortal Samsara Schema** ‚Äî crash-resistant, self-healing, and eternal.
#[derive(Clone)]
pub struct SqliteJobQueue {
    pool: SqlitePool,
}

impl SqliteJobQueue {
    /// Connects to the SQLite database and initializes the WAL mode and schema.
    pub async fn new(db_path: &str) -> Result<Self, FactoryError> {
        use std::str::FromStr;
        let options = SqliteConnectOptions::from_str(db_path)
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Invalid db_path {}: {}", db_path, e) })?
            .create_if_missing(true)
            .journal_mode(SqliteJournalMode::Wal)
            .busy_timeout(Duration::from_millis(5000));

        let pool = SqlitePoolOptions::new()
            .max_connections(5)
            .connect_with(options)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to connect to SQLite: {}", e) })?;

        let queue = Self { pool };
        queue.init_db().await?;
        Ok(queue)
    }

    /// Read-only reference to the connection pool (for advanced queries).
    pub fn pool_ref(&self) -> &SqlitePool {
        &self.pool
    }

    /// The Immortal Samsara Schema (ÂÆåÂÖ®‰∏çÂèØ‰æµDDL)
    /// 
    /// Guardrails implemented at the DB level:
    /// - `CHECK(json_valid(karma_directives))`: Native JSON validation (ÁΩ†3 Èò≤Ë°õ)
    /// - `started_at`: Zombie Process detection (The Zombie Hunter)
    /// - `ON DELETE SET NULL`: Eternal Karma ‚Äî jobs die, lessons live (The Memory Wipe Trap Èò≤Ë°õ)
    /// - `CHECK(weight BETWEEN 0 AND 100)`: Bounded Confidence (The Karma Singularity Èò≤Ë°õ)
    /// - `last_applied_at`: Usage tracking for TTL decay (The Static Decay Trap Èò≤Ë°õ)
    async fn init_db(&self) -> Result<(), FactoryError> {
        // Use CREATE TABLE IF NOT EXISTS to prevent data loss on restart.
        // The old DROP TABLE approach is replaced for production safety.
        sqlx::query(
            "CREATE TABLE IF NOT EXISTS jobs (
                id TEXT PRIMARY KEY, 
                topic TEXT NOT NULL,
                style_name TEXT NOT NULL, 
                karma_directives TEXT NOT NULL CHECK(json_valid(karma_directives)), 
                status TEXT NOT NULL CHECK(status IN ('Pending', 'Processing', 'Completed', 'Failed')),
                started_at TEXT, 
                last_heartbeat TEXT,
                tech_karma_extracted INTEGER NOT NULL DEFAULT 0, 
                creative_rating INTEGER CHECK(creative_rating IN (-1, 0, 1)), 
                execution_log TEXT,
                error_message TEXT,
                sns_platform TEXT,
                sns_video_id TEXT,
                published_at TEXT,
                created_at TEXT DEFAULT (datetime('now')),
                updated_at TEXT DEFAULT (datetime('now'))
            );"
        )
        .execute(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to create jobs table: {}", e) })?;

        // Embedded Migrations: safely add columns that may not exist in older schemas.
        // SQLite ALTER TABLE ADD COLUMN errors are silently ignored (idempotent).
        for migration in [
            "ALTER TABLE jobs ADD COLUMN last_heartbeat TEXT",
            "ALTER TABLE jobs ADD COLUMN execution_log TEXT",
            "ALTER TABLE jobs ADD COLUMN sns_platform TEXT",
            "ALTER TABLE jobs ADD COLUMN sns_video_id TEXT",
            "ALTER TABLE jobs ADD COLUMN published_at TEXT",
            "ALTER TABLE jobs ADD COLUMN retry_count INTEGER NOT NULL DEFAULT 0",
            "ALTER TABLE jobs ADD COLUMN output_videos TEXT",
        ] {
            let _ = sqlx::query(migration).execute(&self.pool).await;
        }

        sqlx::query(
            "CREATE TABLE IF NOT EXISTS karma_logs (
                id TEXT PRIMARY KEY,
                job_id TEXT, 
                karma_type TEXT NOT NULL CHECK(karma_type IN ('Technical', 'Creative', 'Synthesized')),
                related_skill TEXT NOT NULL, 
                lesson TEXT NOT NULL,        
                weight INTEGER NOT NULL DEFAULT 100 CHECK(weight BETWEEN 0 AND 100), 
                last_applied_at TEXT DEFAULT (datetime('now')),
                created_at TEXT DEFAULT (datetime('now')),
                FOREIGN KEY(job_id) REFERENCES jobs(id) ON DELETE SET NULL
            );"
        )
        .execute(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to create karma_logs table: {}", e) })?;

        // Indices for optimal performance
        sqlx::query("CREATE INDEX IF NOT EXISTS idx_jobs_status_started ON jobs(status, started_at);")
            .execute(&self.pool).await.ok();
        sqlx::query("CREATE INDEX IF NOT EXISTS idx_karma_logs_skill_weight ON karma_logs(related_skill, weight DESC);")
            .execute(&self.pool).await.ok();
        
        // The Metrics Ledger (Ë©ï‰æ°Âè∞Â∏≥)
        // Stores chronological snapshots of SNS performance at milestones (24h, 7d, 30d).
        sqlx::query(
            "CREATE TABLE IF NOT EXISTS sns_metrics_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                job_id TEXT NOT NULL,
                milestone_days INTEGER NOT NULL,
                views INTEGER NOT NULL,
                likes INTEGER NOT NULL,
                comments_count INTEGER NOT NULL,
                raw_comments_json TEXT,
                oracle_score_topic REAL,
                oracle_score_visual REAL,
                oracle_score_soul REAL,
                oracle_reason TEXT,
                is_finalized INTEGER NOT NULL DEFAULT 0,
                recorded_at TEXT DEFAULT (datetime('now')),
                FOREIGN KEY(job_id) REFERENCES jobs(id) ON DELETE CASCADE
            );"
        ).execute(&self.pool).await.map_err(|e| FactoryError::Infrastructure {
            reason: format!("Failed to create sns_metrics_history: {}", e),
        })?;

        sqlx::query("CREATE INDEX IF NOT EXISTS idx_sns_metrics_job ON sns_metrics_history(job_id, milestone_days);")
            .execute(&self.pool).await.ok();

        // New migrations for sns_metrics_history refinement
        for migration in [
            "ALTER TABLE sns_metrics_history ADD COLUMN raw_comments_json TEXT",
            "ALTER TABLE sns_metrics_history ADD COLUMN is_finalized INTEGER NOT NULL DEFAULT 0",
            "ALTER TABLE sns_metrics_history ADD COLUMN retry_count INTEGER NOT NULL DEFAULT 0",
            "ALTER TABLE karma_logs ADD COLUMN soul_version_hash TEXT",
        ] {
            let _ = sqlx::query(migration).execute(&self.pool).await;
        }
        
        // --- Phase 12: Project Ani Foundation ---
        sqlx::query(
            "CREATE TABLE IF NOT EXISTS agent_stats (
                id INTEGER PRIMARY KEY CHECK (id = 1),
                level INTEGER NOT NULL DEFAULT 1,
                exp INTEGER NOT NULL DEFAULT 0,
                affection INTEGER NOT NULL DEFAULT 0,
                intimacy INTEGER NOT NULL DEFAULT 0,
                fatigue INTEGER NOT NULL DEFAULT 0,
                updated_at TEXT DEFAULT (datetime('now'))
            );"
        )
        .execute(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to create agent_stats table: {}", e) })?;

        // Seed initial data if table is empty
        let _ = sqlx::query("INSERT OR IGNORE INTO agent_stats (id, level, exp, affection, intimacy, fatigue) VALUES (1, 1, 0, 0, 0, 0);")
            .execute(&self.pool)
            .await;

        // The Temporal Voids protection: Global Circuit Breaker State
        sqlx::query(
            "CREATE TABLE IF NOT EXISTS system_state (
                key TEXT PRIMARY KEY,
                value TEXT NOT NULL,
                updated_at TEXT DEFAULT (datetime('now'))
            );"
        )
        .execute(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to create system_state table: {}", e) })?;

        // --- Watchtower Memory Distillation Tables ---
        sqlx::query(
            "CREATE TABLE IF NOT EXISTS chat_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                channel_id TEXT NOT NULL,
                role TEXT NOT NULL CHECK(role IN ('user', 'assistant', 'system')),
                content TEXT NOT NULL,
                is_distilled INTEGER NOT NULL DEFAULT 0,
                created_at TEXT DEFAULT (datetime('now'))
            );"
        )
        .execute(&self.pool).await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to create chat_history: {}", e) })?;

        sqlx::query("CREATE INDEX IF NOT EXISTS idx_chat_history_channel ON chat_history(channel_id, created_at DESC);")
            .execute(&self.pool).await.ok();
        sqlx::query("CREATE INDEX IF NOT EXISTS idx_chat_history_undistilled ON chat_history(is_distilled) WHERE is_distilled = 0;")
            .execute(&self.pool).await.ok();

        sqlx::query(
            "CREATE TABLE IF NOT EXISTS chat_memory_summaries (
                channel_id TEXT PRIMARY KEY,
                summary TEXT NOT NULL,
                updated_at TEXT DEFAULT (datetime('now'))
            );"
        )
        .execute(&self.pool).await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to create chat_memory_summaries: {}", e) })?;

        Ok(())
    }
}

#[async_trait]
impl JobQueue for SqliteJobQueue {
    async fn enqueue(&self, topic: &str, style: &str, karma_directives: Option<&str>) -> Result<String, FactoryError> {
        let id = Uuid::new_v4().to_string();
        let now = Utc::now().to_rfc3339();
        // Default to empty JSON object if None, satisfying CHECK(json_valid(...))
        let directives = karma_directives.unwrap_or("{}");

        sqlx::query(
            "INSERT INTO jobs (id, topic, style_name, karma_directives, status, created_at, updated_at) VALUES (?, ?, ?, ?, ?, ?, ?)"
        )
        .bind(&id)
        .bind(topic)
        .bind(style)
        .bind(directives)
        .bind(JobStatus::Pending.to_string())
        .bind(&now)
        .bind(&now)
        .execute(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to enqueue job: {}", e) })?;

        Ok(id)
    }

    async fn fetch_job(&self, job_id: &str) -> Result<Option<Job>, FactoryError> {
        let row = sqlx::query(
            "SELECT id, topic, style_name, karma_directives, status, started_at, last_heartbeat, tech_karma_extracted, creative_rating, execution_log, error_message, sns_platform, sns_video_id, published_at, output_videos FROM jobs WHERE id = ?"
        )
        .bind(job_id)
        .fetch_optional(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to fetch job {}: {}", job_id, e) })?;

        if let Some(r) = row {
            let id: String = r.get("id");
            let topic: String = r.get("topic");
            let style: String = r.get("style_name");
            let karma_directives: Option<String> = try_get_optional_string(&r, "karma_directives");
            let tech_karma_extracted: i32 = r.get("tech_karma_extracted");
            let creative_rating: Option<i32> = r.try_get("creative_rating").ok();
            let execution_log: Option<String> = try_get_optional_string(&r, "execution_log");
            let error_message: Option<String> = try_get_optional_string(&r, "error_message");
            let sns_platform: Option<String> = try_get_optional_string(&r, "sns_platform");
            let sns_video_id: Option<String> = try_get_optional_string(&r, "sns_video_id");
            let published_at: Option<String> = try_get_optional_string(&r, "published_at");
            let output_videos: Option<String> = try_get_optional_string(&r, "output_videos");
            let status_str: String = r.get("status");
            let status = JobStatus::from_string(&status_str);

            Ok(Some(Job {
                id,
                topic,
                style,
                karma_directives,
                status,
                started_at: r.get("started_at"),
                last_heartbeat: r.get("last_heartbeat"),
                tech_karma_extracted: tech_karma_extracted != 0,
                creative_rating,
                execution_log,
                error_message,
                sns_platform,
                sns_video_id,
                published_at,
                output_videos,
            }))
        } else {
            Ok(None)
        }
    }

    async fn dequeue(&self) -> Result<Option<Job>, FactoryError> {
        let mut tx = self.pool.begin().await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to start transaction: {}", e) })?;

        let row = sqlx::query(
            "SELECT id, topic, style_name, karma_directives, status, started_at, last_heartbeat, tech_karma_extracted, creative_rating, execution_log, error_message, sns_platform, sns_video_id, published_at, output_videos FROM jobs WHERE status = ? ORDER BY created_at ASC LIMIT 1"
        )
        .bind(JobStatus::Pending.to_string())
        .fetch_optional(&mut *tx)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to fetch pending job: {}", e) })?;

        if let Some(r) = row {
            let id: String = r.get("id");
            let topic: String = r.get("topic");
            let style: String = r.get("style_name");
            let karma_directives: Option<String> = try_get_optional_string(&r, "karma_directives");
            let tech_karma_extracted: i32 = r.get("tech_karma_extracted");
            let creative_rating: Option<i32> = r.try_get("creative_rating").ok();
            let execution_log: Option<String> = try_get_optional_string(&r, "execution_log");
            let error_message: Option<String> = try_get_optional_string(&r, "error_message");
            let sns_platform: Option<String> = try_get_optional_string(&r, "sns_platform");
            let sns_video_id: Option<String> = try_get_optional_string(&r, "sns_video_id");
            let published_at: Option<String> = try_get_optional_string(&r, "published_at");
            let output_videos: Option<String> = try_get_optional_string(&r, "output_videos");

            let now = Utc::now().to_rfc3339();
            // Set status to Processing, record started_at AND first heartbeat
            sqlx::query("UPDATE jobs SET status = ?, started_at = ?, last_heartbeat = ?, updated_at = ? WHERE id = ?")
                .bind(JobStatus::Processing.to_string())
                .bind(&now)
                .bind(&now)
                .bind(&now)
                .bind(&id)
                .execute(&mut *tx)
                .await
                .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to update job status: {}", e) })?;

            tx.commit().await
                .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to commit transaction: {}", e) })?;

            Ok(Some(Job {
                id,
                topic,
                style,
                karma_directives,
                status: JobStatus::Processing,
                started_at: Some(now.clone()),
                last_heartbeat: Some(now),
                tech_karma_extracted: tech_karma_extracted != 0,
                creative_rating,
                execution_log,
                error_message,
                sns_platform,
                sns_video_id,
                published_at,
                output_videos,
            }))
        } else {
            Ok(None)
        }
    }

    async fn complete_job(&self, job_id: &str, output_videos: Option<&str>) -> Result<(), FactoryError> {
        let now = Utc::now().to_rfc3339();
        sqlx::query("UPDATE jobs SET status = ?, output_videos = ?, updated_at = ? WHERE id = ?")
            .bind(JobStatus::Completed.to_string())
            .bind(output_videos)
            .bind(&now)
            .bind(job_id)
            .execute(&self.pool)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to complete job {}: {}", job_id, e) })?;
        Ok(())
    }

    async fn fail_job(&self, job_id: &str, reason: &str) -> Result<(), FactoryError> {
        let now = Utc::now().to_rfc3339();
        sqlx::query("UPDATE jobs SET status = ?, error_message = ?, updated_at = ? WHERE id = ?")
            .bind(JobStatus::Failed.to_string())
            .bind(reason)
            .bind(&now)
            .bind(job_id)
            .execute(&self.pool)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to fail job {}: {}", job_id, e) })?;
        Ok(())
    }

    async fn fetch_relevant_karma(&self, topic: &str, skill_id: &str, limit: i64, current_soul_hash: &str) -> Result<Vec<String>, FactoryError> {
        // Boltzmann RAG: Time-Decay Karma Injection
        // - effective_weight = max(0, weight - days_since_creation * 0.5)
        // - Older karma naturally fades, preventing the Success Trap
        // - Fresh insights are always prioritized
        let topic_pattern = format!("%{}%", topic);

        let rows = sqlx::query(
            "SELECT id, lesson, soul_version_hash,
              max(0, weight - (julianday('now') - julianday(created_at)) * 0.5) AS effective_weight
             FROM karma_logs 
             WHERE weight > 0 AND (related_skill = ? OR related_skill = 'global' OR lesson LIKE ?) 
             ORDER BY effective_weight DESC, created_at DESC LIMIT ?"
        )
        .bind(skill_id)
        .bind(&topic_pattern)
        .bind(limit)
        .fetch_all(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to fetch relevant karma: {}", e) })?;

        let mut karma = Vec::new();
        for row in &rows {
            let lesson: String = row.get("lesson");
            let karma_hash: Option<String> = try_get_optional_string(row, "soul_version_hash");
            
            let mut processed_lesson = lesson;
            if let Some(h) = karma_hash {
                // The Cognitive Dissonance Trap Fix: Warn LLM if this karma is from a different era
                if h != current_soul_hash {
                    processed_lesson = format!("[LEGACY KARMA - from an older Soul version]\n{}", processed_lesson);
                }
            }
            karma.push(processed_lesson);
        }

        // Update last_applied_at for applied karma entries (Usage Tracking for TTL Decay)
        let now = Utc::now().to_rfc3339();
        for row in &rows {
            let karma_id: String = row.get("id");
            let _ = sqlx::query("UPDATE karma_logs SET last_applied_at = ? WHERE id = ?")
                .bind(&now)
                .bind(&karma_id)
                .execute(&self.pool)
                .await;
        }

        Ok(karma)
    }

    async fn store_karma(&self, job_id: &str, skill_id: &str, lesson: &str, karma_type: &str, soul_hash: &str) -> Result<(), FactoryError> {
        let id = Uuid::new_v4().to_string();
        let now = Utc::now().to_rfc3339();
        sqlx::query(
            "INSERT INTO karma_logs (id, job_id, karma_type, related_skill, lesson, soul_version_hash, created_at) VALUES (?, ?, ?, ?, ?, ?, ?)"
        )
        .bind(&id)
        .bind(job_id)
        .bind(karma_type)
        .bind(skill_id)
        .bind(lesson)
        .bind(soul_hash)
        .bind(&now)
        .execute(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to store karma for job {}: {}", job_id, e) })?;
        Ok(())
    }

    /// The Zombie Hunter (Heartbeat Edition): Reclaims jobs whose heartbeat has gone silent.
    /// Uses `last_heartbeat` instead of `started_at`, preventing false kills on long-running jobs.
    async fn reclaim_zombie_jobs(&self, timeout_minutes: i64) -> Result<u64, FactoryError> {
        let now = Utc::now().to_rfc3339();
        let result = sqlx::query(
            "UPDATE jobs SET status = 'Failed', error_message = 'Zombie reclaimed: heartbeat timeout exceeded', updated_at = ? 
             WHERE status = 'Processing' 
             AND last_heartbeat IS NOT NULL 
             AND (julianday('now') - julianday(last_heartbeat)) * 24 * 60 > ?"
        )
        .bind(&now)
        .bind(timeout_minutes)
        .execute(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to reclaim zombie jobs: {}", e) })?;

        let count = result.rows_affected();
        if count > 0 {
            tracing::warn!("üßü Zombie Hunter: Reclaimed {} ghost job(s)", count);
        }
        Ok(count)
    }

    /// Sets the creative rating for a completed job (Human-in-the-Loop, Asynchronous Karma).
    /// Atomic Guard: Only Completed or Processing jobs can receive ratings.
    async fn set_creative_rating(&self, job_id: &str, rating: i32) -> Result<(), FactoryError> {
        let now = Utc::now().to_rfc3339();
        let result = sqlx::query(
            "UPDATE jobs SET creative_rating = ?, updated_at = ? WHERE id = ? AND status IN ('Completed', 'Processing')"
        )
        .bind(rating)
        .bind(&now)
        .bind(job_id)
        .execute(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to set creative rating for job {}: {}", job_id, e) })?;

        if result.rows_affected() == 0 {
            return Err(FactoryError::Infrastructure {
                reason: format!("Atomic Guard: Job '{}' is not in Completed/Processing state, rating rejected", job_id),
            });
        }
        Ok(())
    }

    /// The Heartbeat Pulse: Worker calls this periodically to prove it's alive.
    async fn heartbeat_pulse(&self, job_id: &str) -> Result<(), FactoryError> {
        let now = Utc::now().to_rfc3339();
        sqlx::query("UPDATE jobs SET last_heartbeat = ?, updated_at = ? WHERE id = ?")
            .bind(&now)
            .bind(&now)
            .bind(job_id)
            .execute(&self.pool)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to pulse heartbeat for job {}: {}", job_id, e) })?;
        Ok(())
    }

    /// Log-First Distillation: Stores the execution log in the DB.
    async fn store_execution_log(&self, job_id: &str, log: &str) -> Result<(), FactoryError> {
        let now = Utc::now().to_rfc3339();
        sqlx::query("UPDATE jobs SET execution_log = ?, updated_at = ? WHERE id = ?")
            .bind(log)
            .bind(&now)
            .bind(job_id)
            .execute(&self.pool)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to store execution log for job {}: {}", job_id, e) })?;
        Ok(())
    }

    /// Deferred Distillation: Find completed/failed jobs with logs but no karma extracted yet.
    async fn fetch_undistilled_jobs(&self, limit: i64) -> Result<Vec<Job>, FactoryError> {
        let rows = sqlx::query(
            "SELECT id, topic, style_name, karma_directives, status, started_at, last_heartbeat, 
                     tech_karma_extracted, creative_rating, execution_log, error_message,
                     sns_platform, sns_video_id, published_at, output_videos 
              FROM jobs 
              WHERE execution_log IS NOT NULL 
              AND tech_karma_extracted = 0 
              AND status IN ('Completed', 'Failed') 
              ORDER BY updated_at ASC LIMIT ?"
        )
        .bind(limit)
        .fetch_all(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to fetch undistilled jobs: {}", e) })?;

        let mut jobs = Vec::new();
        for r in rows {
            let tech_karma_extracted: i32 = r.get("tech_karma_extracted");
            jobs.push(Job {
                id: r.get("id"),
                topic: r.get("topic"),
                style: r.get("style_name"),
                karma_directives: try_get_optional_string(&r, "karma_directives"),
                status: match r.get::<String, _>("status").as_str() {
                    "Completed" => JobStatus::Completed,
                    "Failed" => JobStatus::Failed,
                    _ => JobStatus::Pending,
                },
                started_at: try_get_optional_string(&r, "started_at"),
                last_heartbeat: try_get_optional_string(&r, "last_heartbeat"),
                tech_karma_extracted: tech_karma_extracted != 0,
                creative_rating: r.try_get("creative_rating").ok(),
                execution_log: try_get_optional_string(&r, "execution_log"),
                error_message: try_get_optional_string(&r, "error_message"),
                sns_platform: try_get_optional_string(&r, "sns_platform"),
                sns_video_id: try_get_optional_string(&r, "sns_video_id"),
                published_at: try_get_optional_string(&r, "published_at"),
                output_videos: try_get_optional_string(&r, "output_videos"),
            });
        }
        Ok(jobs)
    }

    /// Marks a job as having had its karma extracted (tech_karma_extracted = 1).
    async fn mark_karma_extracted(&self, job_id: &str) -> Result<(), FactoryError> {
        let now = Utc::now().to_rfc3339();
        sqlx::query("UPDATE jobs SET tech_karma_extracted = 1, updated_at = ? WHERE id = ?")
            .bind(&now)
            .bind(job_id)
            .execute(&self.pool)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to mark karma extracted for job {}: {}", job_id, e) })?;
        Ok(())
    }

    /// DB Scavenger: Purge Completed/Failed jobs older than `days` days.
    /// karma_logs survive via ON DELETE SET NULL (Eternal Karma ‚Äî jobs die, lessons live).
    /// Rigid Review: Purge threshold is typically >30 days (e.g. 60) to prevent the Watcher from losing targets.
    async fn purge_old_jobs(&self, days: i64) -> Result<u64, FactoryError> {
        let result = sqlx::query(
            "DELETE FROM jobs WHERE status IN ('Completed', 'Failed') AND created_at < datetime('now', ? || ' days')"
        )
        .bind(format!("-{}", days))
        .execute(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to purge old jobs: {}", e) })?;

        let purged = result.rows_affected();

        // Optimize DB after purge (lightweight alternative to VACUUM for WAL mode)
        let _ = sqlx::query("PRAGMA optimize;").execute(&self.pool).await;

        Ok(purged)
    }

    async fn link_sns_data(&self, job_id: &str, platform: &str, video_id: &str) -> Result<(), FactoryError> {
        let now = Utc::now().to_rfc3339();
        sqlx::query("UPDATE jobs SET sns_platform = ?, sns_video_id = ?, published_at = ?, updated_at = ? WHERE id = ?")
            .bind(platform)
            .bind(video_id)
            .bind(&now)
            .bind(&now)
            .bind(job_id)
            .execute(&self.pool)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to link SNS data for job {}: {}", job_id, e) })?;
        Ok(())
    }

    async fn fetch_jobs_for_evaluation(&self, milestone_days: i64, limit: i64) -> Result<Vec<Job>, FactoryError> {
        // The Catch-up Logic: State-based query that finds jobs past their milestone without a record.
        let rows = sqlx::query(
            "SELECT id, topic, style_name, karma_directives, status, started_at, last_heartbeat, 
                     tech_karma_extracted, creative_rating, execution_log, error_message,
                     sns_platform, sns_video_id, published_at, output_videos 
              FROM jobs 
              WHERE sns_platform IS NOT NULL 
              AND sns_video_id IS NOT NULL 
              AND published_at IS NOT NULL
              AND published_at <= datetime('now', ? || ' days')
              AND id NOT IN (SELECT job_id FROM sns_metrics_history WHERE milestone_days = ?)
              ORDER BY published_at ASC LIMIT ?"
        )
        .bind(format!("-{}", milestone_days))
        .bind(milestone_days)
        .bind(limit)
        .fetch_all(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to fetch jobs for evaluation: {}", e) })?;

        let mut jobs = Vec::new();
        for r in rows {
            let tech_karma_extracted: i32 = r.get("tech_karma_extracted");
            jobs.push(Job {
                id: r.get("id"),
                topic: r.get("topic"),
                style: r.get("style_name"),
                karma_directives: try_get_optional_string(&r, "karma_directives"),
                status: match r.get::<String, _>("status").as_str() {
                    "Completed" => JobStatus::Completed,
                    "Failed" => JobStatus::Failed,
                    _ => JobStatus::Pending,
                },
                started_at: try_get_optional_string(&r, "started_at"),
                last_heartbeat: try_get_optional_string(&r, "last_heartbeat"),
                tech_karma_extracted: tech_karma_extracted != 0,
                creative_rating: r.try_get("creative_rating").ok(),
                execution_log: try_get_optional_string(&r, "execution_log"),
                error_message: try_get_optional_string(&r, "error_message"),
                sns_platform: try_get_optional_string(&r, "sns_platform"),
                sns_video_id: try_get_optional_string(&r, "sns_video_id"),
                published_at: try_get_optional_string(&r, "published_at"),
                output_videos: try_get_optional_string(&r, "output_videos"),
            });
        }
        Ok(jobs)
    }

    #[allow(clippy::too_many_arguments)]
    async fn record_sns_metrics(
        &self,
        job_id: &str,
        milestone_days: i64,
        views: i64,
        likes: i64,
        comments_count: i64,
        raw_comments: Option<&str>,
    ) -> Result<(), FactoryError> {
        sqlx::query(
            "INSERT INTO sns_metrics_history (job_id, milestone_days, views, likes, comments_count, raw_comments_json)
             VALUES (?, ?, ?, ?, ?, ?)"
        )
        .bind(job_id)
        .bind(milestone_days)
        .bind(views)
        .bind(likes)
        .bind(comments_count)
        .bind(raw_comments)
        .execute(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to record SNS metrics: {}", e) })?;
        Ok(())
    }
    async fn fetch_pending_evaluations(&self, limit: i64) -> Result<Vec<SnsMetricsRecord>, FactoryError> {
        let rows = sqlx::query(
            "SELECT id, job_id, milestone_days, views, likes, comments_count, raw_comments_json
             FROM sns_metrics_history
             WHERE is_finalized = 0
             LIMIT ?"
        )
        .bind(limit)
        .fetch_all(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to fetch pending evaluations: {}", e) })?;

        let mut out = Vec::new();
        for row in rows {
            out.push(SnsMetricsRecord {
                id: row.get("id"),
                job_id: row.get("job_id"),
                milestone_days: row.get("milestone_days"),
                views: row.get("views"),
                likes: row.get("likes"),
                comments_count: row.get("comments_count"),
                raw_comments_json: row.get("raw_comments_json"),
            });
        }
        Ok(out)
    }

    async fn apply_final_verdict(
        &self,
        record_id: i64,
        verdict: OracleVerdict,
        soul_hash: &str,
    ) -> Result<(), FactoryError> {
        let mut tx = self.pool.begin().await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to start transaction: {}", e) })?;

        // 1. Update the Metrics Ledger (The Proof)
        sqlx::query(
            "UPDATE sns_metrics_history 
             SET oracle_score_topic = ?, oracle_score_visual = ?, oracle_score_soul = ?, oracle_reason = ?, is_finalized = 1
             WHERE id = ?"
        )
        .bind(verdict.topic_score)
        .bind(verdict.visual_score)
        .bind(verdict.soul_score)
        .bind(&verdict.reasoning)
        .bind(record_id)
        .execute(&mut *tx)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to update ledger: {}", e) })?;

        // 2. Fetch job info for Karma update
        let job_row = sqlx::query(
            "SELECT j.id, j.topic, j.style_name, h.milestone_days 
             FROM jobs j 
             JOIN sns_metrics_history h ON j.id = h.job_id 
             WHERE h.id = ?"
        )
        .bind(record_id)
        .fetch_one(&mut *tx)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to fetch job context: {}", e) })?;

        let job_id: String = job_row.get("id");
        let topic: String = job_row.get("topic");
        let style_name: String = job_row.get("style_name");
        let milestone_days: i64 = job_row.get("milestone_days");

        // 3. If it's the Final Verdict (30d), store the lesson in Karma Logs
        // Average Engagement * Soul Score => Weight (0-100)
        if milestone_days == 30 {
            // Semantic Karma Refinement (The Semantic Void ‰øÆÊ≠£)
            // „ÇÇ„ÅóÈ≠Ç„ÅåÊ±öÊüì„Åï„Çå„Å¶„ÅÑ„Åü„Çâ„ÄÅOracle„ÅÆÁêÜÁî±„Çí„ÄåÊñ∞„Åü„Å™Êàí„ÇÅ„Äç„Å®„Åó„Å¶ÊúÄÈ´òÂÑ™ÂÖàÂ∫¶„ÅßÂè©„ÅçËæº„ÇÄ
            if verdict.soul_score <= 0.5 {
                let karma_id = Uuid::new_v4().to_string();
                let lesson = format!("SOUL VIOLATION / È≠Ç„ÅÆÊ±öÊüì: {}", verdict.reasoning);
                
                sqlx::query(
                    "INSERT INTO karma_logs (id, job_id, karma_type, related_skill, lesson, weight, soul_version_hash)
                     VALUES (?, ?, ?, ?, ?, ?, ?)"
                )
                .bind(&karma_id)
                .bind(&job_id)
                .bind("Synthesized") // Êñ∞„Åü„Å™Âè°Êô∫„ÉªÊàí„ÇÅ„Å®„Åó„Å¶ÂêàÊàê
                .bind(&style_name) // „Åì„Åì„Åß„ÅÆÈñ¢ÈÄ£„Çπ„Ç≠„É´„ÅØÊò†ÂÉè„Çπ„Çø„Ç§„É´
                .bind(&lesson)
                .bind(100) // Áµ∂ÂØæÁöÑ„Å™Êéü„Å®„Åó„Å¶ RAG „ÅÆ„Éà„ÉÉ„Éó„Å´Âõ∫ÂÆö
                .bind(soul_hash)
                .execute(&mut *tx)
                .await
                .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to inject Semantic Refinement: {}", e) })?;
            }
            let avg_engagement = (verdict.topic_score + verdict.visual_score) / 2.0;
            let calculated_weight = (50.0 + (avg_engagement * verdict.soul_score * 50.0)) as i64;
            let weight = calculated_weight.clamp(0, 100);

            sqlx::query(
                "INSERT INTO karma_logs (job_id, topic, style_name, lesson, weight, soul_version_hash)
                 VALUES (?, ?, ?, ?, ?, ?)"
            )
            .bind(&job_id)
            .bind(&topic)
            .bind(&style_name)
            .bind(&verdict.reasoning)
            .bind(weight)
            .bind(soul_hash)
            .execute(&mut *tx)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to update Karma logs: {}", e) })?;
        }

        tx.commit().await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to commit transaction: {}", e) })?;

        Ok(())
    }

    async fn fetch_recent_jobs(&self, limit: i64) -> Result<Vec<Job>, FactoryError> {
        let rows = sqlx::query(
            "SELECT id, topic, style_name, karma_directives, status, started_at, last_heartbeat, 
                     tech_karma_extracted, creative_rating, execution_log, error_message,
                     sns_platform, sns_video_id, published_at, output_videos 
              FROM jobs 
              ORDER BY created_at DESC LIMIT ?"
        )
        .bind(limit)
        .fetch_all(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to fetch recent jobs: {}", e) })?;

        let mut jobs = Vec::new();
        for r in rows {
            let tech_karma_extracted: i32 = r.get("tech_karma_extracted");
            jobs.push(Job {
                id: r.get("id"),
                topic: r.get("topic"),
                style: r.get("style_name"),
                karma_directives: try_get_optional_string(&r, "karma_directives"),
                status: JobStatus::from_string(r.get::<String, _>("status").as_str()),
                started_at: try_get_optional_string(&r, "started_at"),
                last_heartbeat: try_get_optional_string(&r, "last_heartbeat"),
                tech_karma_extracted: tech_karma_extracted != 0,
                creative_rating: r.try_get("creative_rating").ok(),
                execution_log: try_get_optional_string(&r, "execution_log"),
                error_message: try_get_optional_string(&r, "error_message"),
                sns_platform: try_get_optional_string(&r, "sns_platform"),
                sns_video_id: try_get_optional_string(&r, "sns_video_id"),
                published_at: try_get_optional_string(&r, "published_at"),
                output_videos: try_get_optional_string(&r, "output_videos"),
            });
        }
        Ok(jobs)
    }

    async fn get_agent_stats(&self) -> Result<shared::watchtower::AgentStats, FactoryError> {
        let row = sqlx::query("SELECT level, exp, affection, intimacy, fatigue FROM agent_stats WHERE id = 1")
            .fetch_one(&self.pool)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to fetch agent stats: {}", e) })?;

        use sqlx::Row;
        Ok(shared::watchtower::AgentStats {
            level: row.get("level"),
            exp: row.get("exp"),
            affection: row.get("affection"),
            intimacy: row.get("intimacy"),
            fatigue: row.get("fatigue"),
        })
    }

    async fn add_affection(&self, amount: i32) -> Result<(), FactoryError> {
        sqlx::query("UPDATE agent_stats SET affection = affection + ?, updated_at = datetime('now') WHERE id = 1")
            .bind(amount)
            .execute(&self.pool)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to update affection: {}", e) })?;
        Ok(())
    }

    async fn add_tech_exp(&self, amount: i32) -> Result<(), FactoryError> {
        sqlx::query("UPDATE agent_stats SET exp = exp + ?, updated_at = datetime('now') WHERE id = 1")
            .bind(amount)
            .execute(&self.pool)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to update exp: {}", e) })?;
        Ok(())
    }

    async fn add_intimacy(&self, amount: i32) -> Result<(), FactoryError> {
        sqlx::query("UPDATE agent_stats SET intimacy = intimacy + ?, updated_at = datetime('now') WHERE id = 1")
            .bind(amount)
            .execute(&self.pool)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to update intimacy: {}", e) })?;
        Ok(())
    }
}

impl SqliteJobQueue {
    // --- Ultimate Production Audit: Karma Distillation ---
    pub async fn fetch_skills_for_distillation(&self, threshold: i64) -> Result<Vec<String>, FactoryError> {
        let rows = sqlx::query(
            "SELECT related_skill FROM karma_logs GROUP BY related_skill HAVING COUNT(id) > ?"
        )
        .bind(threshold)
        .fetch_all(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to fetch skills for distillation: {}", e) })?;

        let mut skills = Vec::new();
        for r in rows {
            skills.push(r.try_get("related_skill").unwrap_or_else(|_| "".to_string()));
        }
        Ok(skills)
    }

    pub async fn fetch_raw_karma_for_skill(&self, skill: &str) -> Result<Vec<(String, String)>, FactoryError> {
        let rows = sqlx::query(
            "SELECT id, lesson FROM karma_logs WHERE related_skill = ?"
        )
        .bind(skill)
        .fetch_all(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to fetch raw karma for skill: {}", e) })?;

        let mut karma = Vec::new();
        for r in rows {
            let id: String = try_get_optional_string(&r, "id").unwrap_or_else(|| "".to_string());
            let lesson: String = try_get_optional_string(&r, "lesson").unwrap_or_else(|| "".to_string());
            karma.push((id, lesson));
        }
        Ok(karma)
    }

    pub async fn apply_distilled_karma(&self, skill: &str, distilled_lesson: &str, old_karma_ids: &[String], soul_hash: &str) -> Result<(), FactoryError> {
        let mut tx = self.pool.begin().await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to start tx for distillation: {}", e) })?;

        for id in old_karma_ids {
            sqlx::query("DELETE FROM karma_logs WHERE id = ?").bind(id).execute(&mut *tx).await
                .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to delete old karma {}: {}", id, e) })?;
        }

        let new_id = uuid::Uuid::new_v4().to_string();
        sqlx::query(
            "INSERT INTO karma_logs (id, karma_type, related_skill, lesson, weight, soul_version_hash)
             VALUES (?, 'Synthesized', ?, ?, 100, ?)"
        )
            .bind(&new_id)
            .bind(skill)
            .bind(distilled_lesson)
            .bind(soul_hash)
            .execute(&mut *tx)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to insert synthesized karma: {}", e) })?;

        tx.commit().await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to commit distlillation tx: {}", e) })?;

        Ok(())
    }

    // --- Ultimate Production Audit: Poison Pill (Infinite Billing Loop Defense) ---
    pub async fn increment_job_retry_count(&self, job_id: &str) -> Result<bool, FactoryError> {
        let row = sqlx::query("UPDATE jobs SET retry_count = retry_count + 1 WHERE id = ? RETURNING retry_count")
            .bind(job_id)
            .fetch_one(&self.pool)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to increment job retry count: {}", e) })?;
            
        let count: i64 = row.get("retry_count");
        if count >= 3 {
            sqlx::query("UPDATE jobs SET status = 'Failed', error_message = 'Poison Pill Activated: API continually fails.' WHERE id = ?")
                .bind(job_id)
                .execute(&self.pool).await.ok();
            Ok(true) // Poison pill activated
        } else {
            Ok(false)
        }
    }

    pub async fn increment_oracle_retry_count(&self, record_id: i64) -> Result<bool, FactoryError> {
        let row = sqlx::query("UPDATE sns_metrics_history SET retry_count = retry_count + 1 WHERE id = ? RETURNING retry_count")
            .bind(record_id)
            .fetch_one(&self.pool)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to increment oracle retry count: {}", e) })?;
            
        let count: i64 = row.get("retry_count");
        if count >= 3 {
            sqlx::query("UPDATE sns_metrics_history SET is_finalized = 1, oracle_reason = 'Poison Pill Activated: LLM Evaluation continually fails.' WHERE id = ?")
                .bind(record_id)
                .execute(&self.pool).await.ok();
            Ok(true) // Poison pill activated
        } else {
            Ok(false)
        }
    }

    // --- The Final Wire: Global Circuit Breaker (Mass Extinction Defense) ---
    pub async fn get_global_api_failures(&self) -> Result<i64, FactoryError> {
        let row = sqlx::query("SELECT value FROM system_state WHERE key = 'consecutive_api_failures'")
            .fetch_optional(&self.pool)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to read system_state: {}", e) })?;
        
        if let Some(r) = row {
            let val_str: String = r.try_get("value").unwrap_or_default();
            Ok(val_str.parse().unwrap_or(0))
        } else {
            Ok(0)
        }
    }

    pub async fn record_global_api_failure(&self) -> Result<i64, FactoryError> {
        let current = self.get_global_api_failures().await?;
        let next = current + 1;
        
        sqlx::query(
            "INSERT INTO system_state (key, value, updated_at) 
             VALUES ('consecutive_api_failures', ?, datetime('now'))
             ON CONFLICT(key) DO UPDATE SET value = excluded.value, updated_at = excluded.updated_at"
        )
        .bind(next.to_string())
        .execute(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to update system_state: {}", e) })?;
        
        Ok(next)
    }

    pub async fn record_global_api_success(&self) -> Result<(), FactoryError> {
        sqlx::query(
            "INSERT INTO system_state (key, value, updated_at) 
             VALUES ('consecutive_api_failures', '0', datetime('now'))
             ON CONFLICT(key) DO UPDATE SET value = excluded.value, updated_at = excluded.updated_at"
        )
        .execute(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to reset system_state: {}", e) })?;
        
        Ok(())
    }
}

impl SqliteJobQueue {
    pub async fn fetch_all_karma(&self, limit: i64) -> Result<Vec<serde_json::Value>, FactoryError> {
        // (Existing fetch_all_karma code omitted for brevity; this block replaces the whole method)
        let rows = sqlx::query(
            "SELECT * FROM karma_logs ORDER BY created_at DESC LIMIT ?"
        )
        .bind(limit)
        .fetch_all(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: e.to_string() })?;

        let mut karmas = Vec::new();
        for row in rows {
            use sqlx::Row;
            karmas.push(serde_json::json!({
                "id": row.try_get::<String, _>("id").unwrap_or_default(),
                "job_id": row.try_get::<String, _>("job_id").unwrap_or_default(),
                "skill_id": row.try_get::<String, _>("related_skill").unwrap_or_default(),
                "lesson": row.try_get::<String, _>("lesson").unwrap_or_default(),
                "karma_type": row.try_get::<String, _>("karma_type").unwrap_or_default(),
                "weight": row.try_get::<i64, _>("weight").unwrap_or_default(),
                "created_at": row.try_get::<String, _>("created_at").unwrap_or_default(),
                "last_applied_at": row.try_get::<Option<String>, _>("last_applied_at").unwrap_or_default(),
                "soul_version_hash": row.try_get::<Option<String>, _>("soul_version_hash").unwrap_or_default(),
            }));
        }
        Ok(karmas)
    }

    // --- Watchtower Memory Distillation Methods ---

    pub async fn insert_chat_message(&self, channel_id: &str, role: &str, content: &str) -> Result<(), FactoryError> {
        sqlx::query("INSERT INTO chat_history (channel_id, role, content) VALUES (?, ?, ?)")
            .bind(channel_id)
            .bind(role)
            .bind(content)
            .execute(&self.pool)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to insert chat history: {}", e) })?;
        Ok(())
    }

    pub async fn fetch_chat_history(&self, channel_id: &str, limit: i64) -> Result<Vec<serde_json::Value>, FactoryError> {
        // Fetch the newest `limit` messages, but we need them in chronological order
        // So we order by id DESC, limit, and then reverse the result in memory.
        let rows = sqlx::query(
            "SELECT role, content FROM chat_history WHERE channel_id = ? ORDER BY id DESC LIMIT ?"
        )
        .bind(channel_id)
        .bind(limit)
        .fetch_all(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to fetch chat history: {}", e) })?;

        let mut messages = Vec::new();
        for row in rows {
            use sqlx::Row;
            let role: String = row.get("role");
            let content: String = row.get("content");
            messages.push(serde_json::json!({
                "role": role,
                "content": content
            }));
        }
        
        // Output needs to be chronological (oldest first)
        messages.reverse();
        Ok(messages)
    }

    pub async fn get_chat_memory_summary(&self, channel_id: &str) -> Result<Option<String>, FactoryError> {
        let row = sqlx::query("SELECT summary FROM chat_memory_summaries WHERE channel_id = ?")
            .bind(channel_id)
            .fetch_optional(&self.pool)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to get chat memory summary: {}", e) })?;

        if let Some(r) = row {
            use sqlx::Row;
            Ok(Some(r.get("summary")))
        } else {
            Ok(None)
        }
    }

    pub async fn update_chat_memory_summary(&self, channel_id: &str, summary: &str) -> Result<(), FactoryError> {
        sqlx::query(
            "INSERT INTO chat_memory_summaries (channel_id, summary, updated_at) 
             VALUES (?, ?, datetime('now'))
             ON CONFLICT(channel_id) DO UPDATE SET summary = excluded.summary, updated_at = excluded.updated_at"
        )
        .bind(channel_id)
        .bind(summary)
        .execute(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to update chat memory summary: {}", e) })?;
        Ok(())
    }

    /// Fetches all undistilled chats spanning all channels. 
    /// Returns a map of channel_id to a list of (id, role, content)
    pub async fn fetch_undistilled_chats_by_channel(&self) -> Result<std::collections::HashMap<String, Vec<(i64, String, String)>>, FactoryError> {
        let rows = sqlx::query(
            "SELECT id, channel_id, role, content FROM chat_history WHERE is_distilled = 0 ORDER BY channel_id ASC, id ASC"
        )
        .fetch_all(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to fetch undistilled chats: {}", e) })?;

        let mut map = std::collections::HashMap::new();
        for row in rows {
            use sqlx::Row;
            let id: i64 = row.get("id");
            let channel_id: String = row.get("channel_id");
            let role: String = row.get("role");
            let content: String = row.get("content");
            map.entry(channel_id).or_insert_with(Vec::new).push((id, role, content));
        }
        Ok(map)
    }

    pub async fn mark_chats_as_distilled(&self, channel_id: &str, up_to_id: i64) -> Result<(), FactoryError> {
        sqlx::query("UPDATE chat_history SET is_distilled = 1 WHERE channel_id = ? AND id <= ?")
            .bind(channel_id)
            .bind(up_to_id)
            .execute(&self.pool)
            .await
            .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to mark chats as distilled: {}", e) })?;
        Ok(())
    }

    pub async fn purge_old_distilled_chats(&self, days: i64) -> Result<u64, FactoryError> {
        let result = sqlx::query(
            "DELETE FROM chat_history WHERE is_distilled = 1 AND created_at < datetime('now', ? || ' days')"
        )
        .bind(format!("-{}", days))
        .execute(&self.pool)
        .await
        .map_err(|e| FactoryError::Infrastructure { reason: format!("Failed to purge old distilled chats: {}", e) })?;

        Ok(result.rows_affected())
    }
}

// Helper function because `get` on Option panics if type is unexpected, 
// using try_get is safer if column can be NULL.
fn try_get_optional_string(row: &sqlx::sqlite::SqliteRow, col: &str) -> Option<String> {
    use sqlx::Row;
    row.try_get(col).ok()
}
